#!/usr/bin/env python3
"""
Script de Prueba: Cache RAG Enterprise
Demuestra el sistema de cache sem√°ntico para RAG con mejoras de performance
"""
import asyncio
import time
import json
import httpx
from datetime import datetime
from typing import Dict, Any, List

# Configuraci√≥n
BASE_URL = "http://localhost:8000"
RAG_CACHE_API = f"{BASE_URL}/monitoring/rag-cache"

class RAGCacheTestSuite:
    """Suite de pruebas para el Cache RAG Enterprise"""
    
    def __init__(self):
        self.client = httpx.AsyncClient()
        self.test_results = []
        self.performance_metrics = []
    
    async def run_all_tests(self):
        """Ejecuta todas las pruebas del cache RAG"""
        print("üß† INICIANDO PRUEBAS DEL CACHE RAG ENTERPRISE")
        print("=" * 60)
        
        # Pruebas de funcionalidad
        await self.test_cache_miss_vs_hit()
        await self.test_semantic_similarity()
        await self.test_embedding_cache()
        await self.test_search_cache()
        await self.test_llm_cache()
        await self.test_performance_improvement()
        
        # Mostrar resumen
        await self.show_final_stats()
        
        await self.client.aclose()
    
    async def test_cache_miss_vs_hit(self):
        """Prueba la diferencia entre cache miss y cache hit"""
        print("\n‚ö° TEST 1: Cache Miss vs Cache Hit Performance")
        print("-" * 50)
        
        # Consultas de prueba
        test_queries = [
            "extintores para oficina",
            "cascos de seguridad industrial", 
            "guantes de nitrilo",
            "botas con punta de acero",
            "gafas de protecci√≥n"
        ]
        
        # Primera ronda: Cache MISS (primera vez)
        print("üî¥ PRIMERA RONDA - Cache Miss (consultas nuevas):")
        miss_times = []
        
        for query in test_queries:
            start_time = time.time()
            
            try:
                response = await self.client.post(
                    f"{BASE_URL}/chat/texto",
                    json={
                        "mensaje": query,
                        "chat_id": "test_cache_miss",
                        "usuario_id": 1
                    }
                )
                
                duration = (time.time() - start_time) * 1000
                miss_times.append(duration)
                
                if response.status_code == 200:
                    print(f"   ‚úÖ '{query}': {duration:.0f}ms")
                else:
                    print(f"   ‚ùå '{query}': Error {response.status_code}")
                    
            except Exception as e:
                print(f"   ‚ùå '{query}': Error - {e}")
                miss_times.append(5000)  # Timeout estimado
        
        # Esperar un momento para que se procese el cache
        await asyncio.sleep(2)
        
        # Segunda ronda: Cache HIT (mismas consultas)
        print("\nüü¢ SEGUNDA RONDA - Cache Hit (consultas repetidas):")
        hit_times = []
        
        for query in test_queries:
            start_time = time.time()
            
            try:
                response = await self.client.post(
                    f"{BASE_URL}/chat/texto",
                    json={
                        "mensaje": query,
                        "chat_id": "test_cache_hit",
                        "usuario_id": 1
                    }
                )
                
                duration = (time.time() - start_time) * 1000
                hit_times.append(duration)
                
                if response.status_code == 200:
                    print(f"   ‚úÖ '{query}': {duration:.0f}ms")
                else:
                    print(f"   ‚ùå '{query}': Error {response.status_code}")
                    
            except Exception as e:
                print(f"   ‚ùå '{query}': Error - {e}")
                hit_times.append(1000)  # Estimado
        
        # An√°lisis de performance
        avg_miss = sum(miss_times) / len(miss_times)
        avg_hit = sum(hit_times) / len(hit_times)
        improvement = ((avg_miss - avg_hit) / avg_miss) * 100
        
        print(f"\nüìä AN√ÅLISIS DE PERFORMANCE:")
        print(f"   ‚Ä¢ Promedio Cache Miss: {avg_miss:.0f}ms")
        print(f"   ‚Ä¢ Promedio Cache Hit: {avg_hit:.0f}ms")
        print(f"   ‚Ä¢ Mejora de Performance: {improvement:.1f}%")
        print(f"   ‚Ä¢ Factor de Aceleraci√≥n: {avg_miss/avg_hit:.1f}x")
        
        self.performance_metrics.append({
            "test": "cache_miss_vs_hit",
            "avg_miss_ms": avg_miss,
            "avg_hit_ms": avg_hit,
            "improvement_percent": improvement,
            "speedup_factor": avg_miss/avg_hit
        })
        
        self.test_results.append({
            "test": "cache_miss_vs_hit", 
            "status": "PASSED" if improvement > 20 else "FAILED"
        })
    
    async def test_semantic_similarity(self):
        """Prueba la detecci√≥n de consultas similares"""
        print("\nüß† TEST 2: Detecci√≥n de Consultas Similares")
        print("-" * 50)
        
        # Consultas similares sem√°nticamente
        similar_queries = [
            ("extintores", "extinguidores"),
            ("cascos de seguridad", "cascos protectores"),
            ("guantes nitrilo", "guantes de nitrilo"),
            ("protecci√≥n auditiva", "tapones para o√≠dos"),
            ("botas seguridad", "calzado de seguridad")
        ]
        
        similarity_detected = 0
        
        for original, similar in similar_queries:
            print(f"\nüîç Probando: '{original}' vs '{similar}'")
            
            # Primera consulta
            start_time = time.time()
            response1 = await self.client.post(
                f"{BASE_URL}/chat/texto",
                json={
                    "mensaje": original,
                    "chat_id": "test_similarity_1",
                    "usuario_id": 1
                }
            )
            time1 = (time.time() - start_time) * 1000
            
            await asyncio.sleep(1)  # Esperar cache
            
            # Consulta similar
            start_time = time.time()
            response2 = await self.client.post(
                f"{BASE_URL}/chat/texto",
                json={
                    "mensaje": similar,
                    "chat_id": "test_similarity_2", 
                    "usuario_id": 1
                }
            )
            time2 = (time.time() - start_time) * 1000
            
            # Verificar si la segunda fue m√°s r√°pida (posible cache hit)
            if time2 < time1 * 0.8:  # 20% m√°s r√°pida
                similarity_detected += 1
                print(f"   ‚úÖ Similaridad detectada: {time1:.0f}ms ‚Üí {time2:.0f}ms")
            else:
                print(f"   ‚ö†Ô∏è No detectada: {time1:.0f}ms ‚Üí {time2:.0f}ms")
        
        detection_rate = (similarity_detected / len(similar_queries)) * 100
        print(f"\nüìä DETECCI√ìN DE SIMILARIDAD:")
        print(f"   ‚Ä¢ Consultas similares detectadas: {similarity_detected}/{len(similar_queries)}")
        print(f"   ‚Ä¢ Tasa de detecci√≥n: {detection_rate:.1f}%")
        
        self.test_results.append({
            "test": "semantic_similarity",
            "status": "PASSED" if detection_rate > 50 else "FAILED"
        })
    
    async def test_embedding_cache(self):
        """Prueba espec√≠fica del cache de embeddings"""
        print("\nüéØ TEST 3: Cache de Embeddings")
        print("-" * 50)
        
        # Obtener m√©tricas antes
        try:
            response = await self.client.get(f"{RAG_CACHE_API}/components")
            if response.status_code == 200:
                before_stats = response.json()
                embedding_hits_before = before_stats["components"]["embeddings"]["hits"]
                embedding_misses_before = before_stats["components"]["embeddings"]["misses"]
                print(f"üìä Antes - Hits: {embedding_hits_before}, Misses: {embedding_misses_before}")
            else:
                print("‚ö†Ô∏è No se pudieron obtener m√©tricas iniciales")
                embedding_hits_before = 0
                embedding_misses_before = 0
        except Exception as e:
            print(f"‚ö†Ô∏è Error obteniendo m√©tricas: {e}")
            embedding_hits_before = 0
            embedding_misses_before = 0
        
        # Realizar consultas para generar embeddings
        test_queries = [
            "productos de seguridad industrial",
            "equipos de protecci√≥n personal",
            "herramientas de trabajo"
        ]
        
        for query in test_queries:
            await self.client.post(
                f"{BASE_URL}/chat/texto",
                json={
                    "mensaje": query,
                    "chat_id": "test_embeddings",
                    "usuario_id": 1
                }
            )
            await asyncio.sleep(0.5)
        
        # Obtener m√©tricas despu√©s
        try:
            response = await self.client.get(f"{RAG_CACHE_API}/components")
            if response.status_code == 200:
                after_stats = response.json()
                embedding_hits_after = after_stats["components"]["embeddings"]["hits"]
                embedding_misses_after = after_stats["components"]["embeddings"]["misses"]
                
                hits_increase = embedding_hits_after - embedding_hits_before
                misses_increase = embedding_misses_after - embedding_misses_before
                
                print(f"üìä Despu√©s - Hits: {embedding_hits_after}, Misses: {embedding_misses_after}")
                print(f"üìà Incremento - Hits: +{hits_increase}, Misses: +{misses_increase}")
                
                if hits_increase > 0 or misses_increase > 0:
                    print("‚úÖ Cache de embeddings funcionando")
                    status = "PASSED"
                else:
                    print("‚ö†Ô∏è No se detect√≥ actividad en cache de embeddings")
                    status = "WARNING"
            else:
                print("‚ùå Error obteniendo m√©tricas finales")
                status = "FAILED"
        except Exception as e:
            print(f"‚ùå Error: {e}")
            status = "FAILED"
        
        self.test_results.append({"test": "embedding_cache", "status": status})
    
    async def test_search_cache(self):
        """Prueba espec√≠fica del cache de b√∫squedas"""
        print("\nüîç TEST 4: Cache de B√∫squedas")
        print("-" * 50)
        
        # Consulta espec√≠fica repetida
        query = "extintores pqs para oficina"
        
        # Primera b√∫squeda (miss)
        start_time = time.time()
        response1 = await self.client.post(
            f"{BASE_URL}/chat/texto",
            json={
                "mensaje": query,
                "chat_id": "test_search_cache_1",
                "usuario_id": 1
            }
        )
        time1 = (time.time() - start_time) * 1000
        
        await asyncio.sleep(1)
        
        # Segunda b√∫squeda (posible hit)
        start_time = time.time()
        response2 = await self.client.post(
            f"{BASE_URL}/chat/texto",
            json={
                "mensaje": query,
                "chat_id": "test_search_cache_2",
                "usuario_id": 1
            }
        )
        time2 = (time.time() - start_time) * 1000
        
        improvement = ((time1 - time2) / time1) * 100 if time1 > 0 else 0
        
        print(f"üîç Consulta: '{query}'")
        print(f"   ‚Ä¢ Primera b√∫squeda: {time1:.0f}ms")
        print(f"   ‚Ä¢ Segunda b√∫squeda: {time2:.0f}ms")
        print(f"   ‚Ä¢ Mejora: {improvement:.1f}%")
        
        status = "PASSED" if improvement > 10 else "WARNING"
        self.test_results.append({"test": "search_cache", "status": status})
    
    async def test_llm_cache(self):
        """Prueba espec√≠fica del cache de respuestas LLM"""
        print("\nü§ñ TEST 5: Cache de Respuestas LLM")
        print("-" * 50)
        
        # Obtener m√©tricas de LLM antes
        try:
            response = await self.client.get(f"{RAG_CACHE_API}/components")
            if response.status_code == 200:
                before_stats = response.json()
                llm_hits_before = before_stats["components"]["llm_responses"]["hits"]
                print(f"üìä LLM Cache Hits antes: {llm_hits_before}")
            else:
                llm_hits_before = 0
        except:
            llm_hits_before = 0
        
        # Realizar consultas que generen respuestas LLM
        llm_queries = [
            "¬øqu√© extintores recomiendas para una oficina?",
            "necesito cascos de seguridad, ¬øcu√°les tienes?",
            "¬øqu√© productos de protecci√≥n auditiva manejan?"
        ]
        
        for query in llm_queries:
            await self.client.post(
                f"{BASE_URL}/chat/texto",
                json={
                    "mensaje": query,
                    "chat_id": "test_llm_cache",
                    "usuario_id": 1
                }
            )
            await asyncio.sleep(1)
        
        # Verificar m√©tricas despu√©s
        try:
            response = await self.client.get(f"{RAG_CACHE_API}/components")
            if response.status_code == 200:
                after_stats = response.json()
                llm_hits_after = after_stats["components"]["llm_responses"]["hits"]
                llm_hit_rate = after_stats["components"]["llm_responses"]["hit_rate"]
                
                print(f"üìä LLM Cache Hits despu√©s: {llm_hits_after}")
                print(f"üìà Hit Rate LLM: {llm_hit_rate:.1f}%")
                
                status = "PASSED" if llm_hits_after > llm_hits_before else "WARNING"
            else:
                status = "FAILED"
        except:
            status = "FAILED"
        
        self.test_results.append({"test": "llm_cache", "status": status})
    
    async def test_performance_improvement(self):
        """Prueba de mejora general de performance"""
        print("\nüöÄ TEST 6: Mejora General de Performance")
        print("-" * 50)
        
        # Obtener m√©tricas de performance
        try:
            response = await self.client.get(f"{RAG_CACHE_API}/performance")
            if response.status_code == 200:
                perf_data = response.json()
                
                hit_rate = perf_data["performance"]["hit_rate"]
                avg_latency = perf_data["performance"]["avg_latency_ms"]
                improvement = perf_data["performance"]["latency_improvement_percent"]
                throughput = perf_data["performance"]["requests_per_second"]
                
                print(f"üìä M√âTRICAS DE PERFORMANCE:")
                print(f"   ‚Ä¢ Hit Rate Global: {hit_rate:.1f}%")
                print(f"   ‚Ä¢ Latencia Promedio: {avg_latency:.1f}ms")
                print(f"   ‚Ä¢ Mejora de Latencia: {improvement:.1f}%")
                print(f"   ‚Ä¢ Throughput: {throughput:.1f} req/s")
                
                # An√°lisis de costos
                cost_reduction = perf_data["cost_analysis"]["overall_cost_reduction"]
                print(f"   ‚Ä¢ Reducci√≥n de Costos: {cost_reduction}")
                
                status = "PASSED" if hit_rate > 30 else "WARNING"
            else:
                print("‚ùå Error obteniendo m√©tricas de performance")
                status = "FAILED"
        except Exception as e:
            print(f"‚ùå Error: {e}")
            status = "FAILED"
        
        self.test_results.append({"test": "performance_improvement", "status": status})
    
    async def show_final_stats(self):
        """Muestra estad√≠sticas finales del cache RAG"""
        print("\nüìä ESTAD√çSTICAS FINALES DEL CACHE RAG")
        print("=" * 60)
        
        try:
            # M√©tricas generales
            response = await self.client.get(RAG_CACHE_API)
            if response.status_code == 200:
                stats = response.json()
                
                overall = stats["stats"]["overall"]
                components = stats["stats"]["by_component"]
                performance = stats["performance"]
                cost_savings = stats["cost_savings"]
                
                print(f"üéØ PERFORMANCE GENERAL:")
                print(f"   ‚Ä¢ Hit Rate Global: {overall['hit_rate']:.1f}%")
                print(f"   ‚Ä¢ Total Requests: {overall['total_requests']}")
                print(f"   ‚Ä¢ Total Hits: {overall['total_hits']}")
                print(f"   ‚Ä¢ Similarity Matches: {overall['similarity_matches']}")
                print(f"   ‚Ä¢ Status: {performance['status'].upper()}")
                
                print(f"\nüß© POR COMPONENTE:")
                for component, data in components.items():
                    print(f"   ‚Ä¢ {component.title()}:")
                    print(f"     - Hits: {data['hits']}")
                    print(f"     - Misses: {data['misses']}")
                    print(f"     - Hit Rate: {data['hit_rate']:.1f}%")
                
                print(f"\nüí∞ AHORRO DE COSTOS:")
                print(f"   ‚Ä¢ Tiempo Total Ahorrado: {cost_savings['total_time_saved_seconds']:.1f}s")
                print(f"   ‚Ä¢ Reducci√≥n Estimada: {cost_savings['estimated_cost_reduction_percent']:.1f}%")
                
                if stats["recommendations"]:
                    print(f"\nüí° RECOMENDACIONES:")
                    for rec in stats["recommendations"]:
                        print(f"   ‚Ä¢ {rec}")
            
        except Exception as e:
            print(f"‚ùå Error obteniendo estad√≠sticas: {e}")
        
        # Resumen de tests
        print(f"\nüß™ RESUMEN DE TESTS:")
        passed = sum(1 for r in self.test_results if r["status"] == "PASSED")
        warning = sum(1 for r in self.test_results if r["status"] == "WARNING")
        failed = sum(1 for r in self.test_results if r["status"] == "FAILED")
        total = len(self.test_results)
        
        print(f"   ‚úÖ Pasaron: {passed}/{total}")
        print(f"   ‚ö†Ô∏è Advertencias: {warning}/{total}")
        print(f"   ‚ùå Fallaron: {failed}/{total}")
        
        for result in self.test_results:
            status_emoji = {"PASSED": "‚úÖ", "WARNING": "‚ö†Ô∏è", "FAILED": "‚ùå"}
            emoji = status_emoji.get(result["status"], "‚ùì")
            print(f"   {emoji} {result['test']}: {result['status']}")
        
        # M√©tricas de performance
        if self.performance_metrics:
            print(f"\n‚ö° M√âTRICAS DE PERFORMANCE:")
            for metric in self.performance_metrics:
                if metric["test"] == "cache_miss_vs_hit":
                    print(f"   ‚Ä¢ Cache Miss vs Hit:")
                    print(f"     - Mejora: {metric['improvement_percent']:.1f}%")
                    print(f"     - Aceleraci√≥n: {metric['speedup_factor']:.1f}x")

async def main():
    """Funci√≥n principal"""
    print("üß† CACHE RAG ENTERPRISE - SUITE DE PRUEBAS")
    print("=" * 60)
    print("Este script demuestra las capacidades del cache RAG sem√°ntico:")
    print("‚Ä¢ Cache de embeddings de consultas")
    print("‚Ä¢ Cache de resultados de b√∫squeda FAISS")
    print("‚Ä¢ Cache de respuestas LLM")
    print("‚Ä¢ Detecci√≥n de consultas similares")
    print("‚Ä¢ Mejoras de performance y reducci√≥n de costos")
    
    # Verificar que el servidor est√© corriendo
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{BASE_URL}/health")
            if response.status_code != 200:
                print(f"‚ùå Servidor no disponible en {BASE_URL}")
                return
    except Exception as e:
        print(f"‚ùå Error conectando al servidor: {e}")
        print("üí° Aseg√∫rate de que el servidor est√© corriendo:")
        print("   python -m uvicorn app.main:app --reload --port 8000")
        return
    
    # Ejecutar tests
    test_suite = RAGCacheTestSuite()
    await test_suite.run_all_tests()
    
    print("\nüéâ PRUEBAS COMPLETADAS")
    print("=" * 60)
    print("El Cache RAG Enterprise est√° funcionando!")
    print(f"üìä Puedes ver m√©tricas en tiempo real en: {RAG_CACHE_API}")

if __name__ == "__main__":
    asyncio.run(main()) 